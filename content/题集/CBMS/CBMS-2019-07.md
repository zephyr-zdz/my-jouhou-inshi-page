# CBMS-2019-07

**题目来源**：[[文字版题库/CBMS/2019#Question 7|2019#Question 7]]
**日期**：2024-07-26
**题目主题**：CS-算法-决策树

## 解题思路

这道题目考察了关于排序算法的决策树性质，主要有三部分：

1. 描述所有决策树中，从根到叶子的路径的最短路径和最长路径。
2. 证明在任何决策树中，所有元素的任意顺序只出现在一个叶子节点中，不会出现在不同的叶子节点中。
3. 证明决策树的高度 $h$ 与元素数量 $n$ 的关系，给出 $h$ 的下界 $c n \log n$，其中 $c$ 是一个常数。

## Solution

### Question 1: Shortest and Longest Paths in Decision Trees

To sort $n$ elements, we need to compare some pairs of elements. Each comparison gives us one bit of information. The shortest path from the root to a leaf in a decision tree corresponds to the minimum number of comparisons needed to determine the order of all elements. The longest path corresponds to the maximum number of comparisons needed.

#### Shortest Path

For the shortest path in a decision tree, we follow a balanced comparison strategy that minimizes the number of comparisons.

1. **Initial Comparison**: Compare $a_1$ with $a_2$.
   - If $a_1 < a_2$, proceed to the next comparison.
   - If $a_1 > a_2$, swap $a_1$ and $a_2$ and then proceed.

2. **Subsequent Comparisons**: Continue comparing each successive pair of elements in the sequence.
   - Compare $a_2$ with $a_3$:
     - If $a_2 < a_3$, continue.
     - If $a_2 > a_3$, place $a_3$ correctly among $a_1$ and $a_2$.
   - Compare $a_3$ with $a_4$, and so on, up to $a_{n-1}$ and $a_n$.

In the most optimal scenario, this process ensures that each comparison immediately determines the relative order of the two elements being compared, with a total of $n-1$ comparisons.

For $n$ elements $a_1, a_2, \ldots, a_n$, the comparisons would look like:

- $a_1 < a_2$
- $a_2 < a_3$
- $a_3 < a_4$
- $\ldots$
- $a_{n-1} < a_n$

In the optimal case, the path has $n-1$ comparisons, leading to the shortest path of length $n-1$.

#### Longest Path

The longest path in a decision tree corresponds to the worst-case scenario where each comparison leads to the maximum possible number of subsequent comparisons. This often occurs when the sequence is in reverse order and we need to sort it into the correct order.

1. **Initial Comparison**: Compare $a_1$ with $a_2$.
   - If $a_1 > a_2$, go to the right child node.
   - Otherwise, go to the left child node.

2. **Subsequent Comparisons**: Continue comparing each pair of elements but always choosing the comparison that leads to the maximum number of steps.
   - Compare $a_1$ with $a_3$:
     - If $a_1 > a_3$, go to the right child node.
     - Otherwise, go to the left child node.
   - Continue this process for all $n$ elements.

In the worst-case scenario, the sequence is completely reversed, requiring $n(n-1)/2$ comparisons to sort it.

For $n$ elements $a_1, a_2, \ldots, a_n$ in reverse order $a_n, a_{n-1}, \ldots, a_1$, the comparisons would look like:

- Compare $a_1$ with $a_2$
  - Compare $a_1$ with $a_3$
    - Compare $a_1$ with $a_4$
    - $\ldots$
    - Compare $a_1$ with $a_n$
- Compare $a_2$ with $a_3$
  - Compare $a_2$ with $a_4$
  - $\ldots$
  - Compare $a_2$ with $a_n$
- $\ldots$
- Compare $a_{n-1}$ with $a_n$

In the worst-case scenario, this process leads to a path with a length of $O(n^2)$ comparisons, representing the longest path in a decision tree.

### Question 2: Unique Order in Decision Trees

#### Existence

In any decision tree used for sorting $n$ elements, each leaf node represents a complete sequence of comparisons that uniquely determines the order of the elements. We need to show that any possible permutation of the $n$ elements appears in at least one leaf node.

**Leaf Node Representation**: Each leaf node corresponds to a unique permutation of the $n$ elements. As we build the tree from the root node, each comparison between two elements $a_i$ and $a_j$ (where $i < j$) directs us to a new child node, either left or right, based on the result of the comparison in the permutation of the elements, until we reach the leaf node.

Thus, each possible permutation of the elements must be represented by at least one path from the root to a leaf. This ensures that any order of all elements appears in one leaf node, satisfying the existence condition.

#### Uniqueness

Now, we need to prove that any given order of all $n$ elements appears in exactly one leaf node and does not appear in multiple leaf nodes.

1. **Unique Comparison Paths**: Each leaf node in a decision tree is reached by a unique sequence of comparisons. This sequence determines a specific permutation of the elements. If two different paths lead to the same permutation, then at least one comparison in the paths, which is located in the common ancestor of the two paths, would have to result in a contradiction.
2. **Deterministic Nature of Comparisons**: Each comparison $a_i < a_j$ or $a_i > a_j$ provides a deterministic outcome. Once the comparison is made, the elements $a_i$ and $a_j$ are placed in a specific order relative to each other. Different sequences of comparisons lead to different permutations.
3. **Conclusion**: Therefore, any given order of all elements appears in exactly one leaf node and does not appear in different leaf nodes. This ensures the uniqueness condition.

### Question 3: Height of the Decision Tree

To prove that $c n \log n \leq h$ for a constant $c$, we consider the following:

1. **Information-Theoretic Argument**: The height of a decision tree represents the maximum number of comparisons needed in the worst case. For $n$ elements, there are $n!$ possible permutations (orders). Each comparison splits the set of possible permutations, providing one bit of information.
2. **Lower Bound on Comparisons**: The number of comparisons needed to distinguish between $n!$ permutations is at least $\log_2(n!)$. Using Stirling's approximation, $n! \approx \sqrt{2\pi n} \left(\frac{n}{e}\right)^n$, we get:

$$
   \log_2(n!) \approx n \log_2(n) - n \log_2(e) + \frac{1}{2} \log_2(2\pi n)
$$

Ignoring lower-order terms, we have:

$$
   \log_2(n!) \approx n \log_2(n)
$$

1. **Height Relation**: The height $h$ of the decision tree must be at least $\log_2(n!)$. Therefore:

$$
   h \geq c n \log n
$$

   where $c$ is a constant that depends on the base of the logarithm and other factors from the Stirling approximation.

Hence, we have shown that the height of the decision tree $h$ satisfies the inequality $c n \log n \leq h$.

## 知识点

#决策树 #排序算法 #复杂度分析 #信息论

## 重点词汇

- Decision Tree 决策树
- Comparison 比较
- Permutation 排列
- Information-Theoretic 信息论的
- Stirling's Approximation 斯特林近似

## 参考资料

1. "Introduction to Algorithms" by Cormen, Leiserson, Rivest, and Stein, Chapter on Sorting and Order Statistics.
2. "The Art of Computer Programming" by Donald Knuth, Volume 3: Sorting and Searching.
