# CBMS-2020-08

**题目来源**：[[做题/文字版题库/CBMS/2020#Question 8|2020#Question 8]]
**日期**：2024-07-23
**题目主题**：Math-线性代数-矩阵特征值与特征向量

## 解题思路

题目要求我们展示矩阵的逆矩阵、特征值和特征向量，并研究矩阵的幂次与特征值和特征向量的关系。我们可以使用相似变换的性质来简化这些问题。

## Solution

### Problem 1: Show the inverse matrix for each of $\mathbf{\Lambda}$ and $A$

Since $\mathbf{\Lambda}$ is a diagonal matrix with diagonal entries $\lambda_{ii}$, its inverse, denoted as $\mathbf{\Lambda}^{-1}$, is also a diagonal matrix. The diagonal entries of $\mathbf{\Lambda}^{-1}$ are the reciprocals of the diagonal entries of $\mathbf{\Lambda}$:

$$
\mathbf{\Lambda}^{-1} = \begin{pmatrix}
\frac{1}{\lambda_{11}} & 0 & \cdots & 0 \\
0 & \frac{1}{\lambda_{22}} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \frac{1}{\lambda_{nn}}
\end{pmatrix}
$$

To find the inverse matrix of $A$, use the given equation $P^{-1}AP = \mathbf{\Lambda}$. Multiply both sides by $P$ and $P^{-1}$ appropriately:

$$
\mathbf{A} = \mathbf{P} \mathbf{\Lambda} \mathbf{P}^{-1}
$$

Taking the inverse of both sides, we get:

$$
\mathbf{A}^{-1} = (\mathbf{P} \mathbf{\Lambda} \mathbf{P}^{-1})^{-1}
$$

Using the property of inverses for matrix products:

$$
\mathbf{A}^{-1} = \mathbf{P} (\mathbf{\Lambda}^{-1}) \mathbf{P}^{-1}
$$

Thus, $\mathbf{A}^{-1}$ is given by:

$$
\mathbf{A}^{-1} = \mathbf{P} \begin{pmatrix}
\frac{1}{\lambda_{11}} & 0 & \cdots & 0 \\
0 & \frac{1}{\lambda_{22}} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \frac{1}{\lambda_{nn}}
\end{pmatrix} \mathbf{P}^{-1}
$$

### Problem 2: Show that $\lambda_{ii}$ is one of the eigenvalues of $\mathbf{A}$, and show one of the corresponding eigenvectors of $\mathbf{A}$

Given the equation $\mathbf{P}^{-1}\mathbf{A}\mathbf{P} = \mathbf{\Lambda}$, this implies that $\mathbf{\Lambda}$ is the diagonal form of $\mathbf{A}$ under the similarity transformation by $P$. The diagonal entries of $\mathbf{\Lambda}$, denoted as $\lambda_{ii}$, are the eigenvalues of $A$.

To show this formally, consider $\mathbf{\Lambda} \mathbf{e}_i = \lambda_{ii} \mathbf{e}_i$, where $\mathbf{e}_i$ is the $i$-th standard basis vector. We have:

$$
\mathbf{\Lambda} \mathbf{e}_i = \begin{pmatrix}
\lambda_{11} & 0 & \cdots & 0 \\
0 & \lambda_{22} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \lambda_{nn}
\end{pmatrix}
\begin{pmatrix}
0 \\
\vdots \\
1 \\
\vdots \\
0
\end{pmatrix}
= \lambda_{ii} \mathbf{e}_i
$$

Since $\mathbf{P}^{-1}\mathbf{AP} = \mathbf{\Lambda}$, let $\mathbf{y}_i = \mathbf{P} \mathbf{e}_i$. Then:

$$
\mathbf{A} \mathbf{y}_i = \mathbf{A} (\mathbf{P} \mathbf{e}_i) = \mathbf{P} (\mathbf{\Lambda} \mathbf{e}_i) = \mathbf{P} (\lambda_{ii} \mathbf{e}_i) = \lambda_{ii} (\mathbf{P} \mathbf{e}_i) = \lambda_{ii} \mathbf{y}_i
$$

Hence, $\mathbf{y}_i = \mathbf{P} \mathbf{e}_i$ is an eigenvector of $\mathbf{A}$ corresponding to the eigenvalue $\lambda_{ii}$.

### Problem 3: Show every pair of eigenvalue and corresponding eigenvector of $\mathbf{A}^k$

From the similarity transformation $\mathbf{P}^{-1}\mathbf{AP} = \mathbf{\Lambda}$, raising both sides to the power $k$ gives:

$$
(\mathbf{P}^{-1}\mathbf{AP})^k = \mathbf{\Lambda}^k
$$

Since $\mathbf{P}^{-1}\mathbf{AP} = \mathbf{\Lambda}$:

$$
\mathbf{P}^{-1}\mathbf{A}^k\mathbf{P} = \mathbf{\Lambda}^k
$$

Because $\mathbf{\Lambda}$ is diagonal, $\mathbf{\Lambda}^k$ is also diagonal, with each diagonal element being raised to the power $k$:

$$
\mathbf{\Lambda}^k = \begin{pmatrix}
\lambda_{11}^k & 0 & \cdots & 0 \\
0 & \lambda_{22}^k & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \lambda_{nn}^k
\end{pmatrix}
$$

Thus, $\mathbf{A}^k$ has the same eigenvectors as $\mathbf{A}$, and the eigenvalues are the $k$-th powers of the eigenvalues of $\mathbf{A}$. Therefore, the eigenvalue-eigenvector pairs for $\mathbf{A}^k$ are:

- Eigenvalue: $\lambda_{ii}^k$
- Corresponding eigenvector: $\mathbf{y}_i = \mathbf{P} \mathbf{e}_i$

In summary, every eigenvalue $\lambda_{ii}$ of $\mathbf{A}$ raised to the power $k$ is an eigenvalue of $\mathbf{A}^k$, and the corresponding eigenvectors remain the same.

## 知识点

#特征值 #特征向量 #相似变换

## 重点词汇

- **Matrix**: 矩阵
- **Eigenvalue**: 特征值
- **Eigenvector**: 特征向量
- **Inverse matrix**: 逆矩阵
- **Diagonal matrix**: 对角矩阵
- **Similarity transformation**: 相似变换

## 参考资料

1. Axler, S. (2015). *Linear Algebra Done Right*. Springer. Chap. 8
2. Strang, G. (2009). *Introduction to Linear Algebra*. Wellesley-Cambridge Press. Chap. 5
